---
title: "Predict_413_Sec55_Homework_2"
author: "Singh, Gurjeet"
date: "February 18, 2018"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    fig_width: 9
    fig_height: 5
    fig_caption: true
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
---

\pagebreak
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE )
library(fpp)
library(tidyverse)

```

# Chapter 7
## Question 1
### Ch7.Q1.a)

The figure below shows the plot of the daily sales of paperback and hardcover books at the same store. The data in the figure below do not display any seasonality for paperback and hardcover books. However, there could some trend here. We will know more once we plug this data into various models.

```{r data_import, echo=F}
### Ch7.Q1.a)
data("books")
autoplot(books) +
  ggtitle("Daily sales of paperback and hardcover books at the same store")

```

### Ch7.Q1.b)

The Table 1 below shows the various matrics from each SES models with different alpha. It appears that as alpha increases, the error increases as well. Hence, alpha = 0.2 works best.

The Table 2 shows the SSE for each models using different alpha.

The figure below shows the four different sets of forecasts.

```{r simple, echo=F}
### Ch7.Q1.b)
fit1_pb <- ses(books[,1], initial = "simple", alpha = 0.2, h=4)
SSE_fit1 <- (accuracy(fit1_pb)[2]^2)*30

fit2_pb <- ses(books[,1], initial = "simple", alpha = 0.4, h=4)
SSE_fit2 <- (accuracy(fit2_pb)[2]^2)*30

fit3_pb <- ses(books[,1], initial = "simple", alpha = 0.6, h=4)
SSE_fit3 <- (accuracy(fit3_pb)[2]^2)*30

fit4_pb <- ses(books[,1], initial = "simple", alpha = 0.8, h=4)
SSE_fit4 <- (accuracy(fit4_pb)[2]^2)*30

Metrics_Values <- rbind.data.frame(accuracy(fit1_pb), accuracy(fit2_pb), accuracy(fit3_pb), 
                                   accuracy(fit4_pb)) 
rownames(Metrics_Values) <- c("alpha = 0.2", "alpha = 0.4", "alpha = 0.6", "alpha = 0.8")
knitr::kable(Metrics_Values, caption = "Metrics from each model")

SSE_Values <- cbind.data.frame(SSE_fit1, SSE_fit2, SSE_fit3, SSE_fit4) 
colnames(SSE_Values) <- c("alpha = 0.2", "alpha = 0.4", "alpha = 0.6", "alpha = 0.8")
rownames(SSE_Values) <- "SSE"
knitr::kable(SSE_Values, caption = "SSE values of each model")

autoplot(books[,1]) +
  autolayer(fitted(fit1_pb), series = "alpha = 0.2") +
autolayer(fitted(fit2_pb), series = "alpha = 0.4") +
autolayer(fitted(fit3_pb), series = "alpha = 0.6") +
  autolayer(fitted(fit4_pb), series = "alpha = 0.8") +
  xlab("Days") + ylab("Paperback Books")

```


### Ch7.Q1.c)

The summary statistic below is from SES model selected the optimal value of alpha. As we mentioned earlier that lower value of alpha gives us the best model, it is quite evident with the result that alpha = 0.1685 gave us the lowest RMSE and SSE.

```{r ses_select, echo=F}
### Ch7.Q1.c)
fit5_pb <- ses(books[,1], h=4)
summary(fit5_pb)
SSE_fit5 <- data.frame((accuracy(fit5_pb)[2]^2)*30)
colnames(SSE_fit5) <- c("alpha = 0.1685")
rownames(SSE_fit5) <- "SSE Value"
knitr::kable(SSE_fit5, caption = "SSE - SES Select")

```


### Ch7.Q1.d)

The summary statistic below shows that with the initial = "optimal" option, we get the same alpha and initial states. There's no difference from SES selecting an optimal value without the option and after setting the optimal option.

```{r ses_select_opt, echo=F}
### Ch7.Q1.d)
fit6_pb <- ses(books[,1], initial = "optimal" ,h=4)
summary(fit6_pb)
SSE_fit6 <- data.frame((accuracy(fit6_pb)[2]^2)*30)
colnames(SSE_fit6) <- c("alpha = 0.1685")
rownames(SSE_fit6) <- "SSE Value"
knitr::kable(SSE_fit6, caption = "SSE - Optimal Select")

```

### Ch7.Q1.e)

We run SES model for Hardcover books. The Table 5 below shows the various matrics from each SES models with different alpha. When alpha = 0.4, the RMSE is the lowest. Hence, forecast works best.

The Table 6 shows the SSE for each models using different alpha. It is clear that alpha = 0.4 gives us the best forecast.

The figure below shows the four different sets of forecasts.

```{r part_B, echo=F}
### Ch7.Q1.e) - Part B
fit1_hc <- ses(books[,2], initial = "simple", alpha = 0.2, h=4)
#summary(fit1_pb)
SSE_fit1_hc <- (accuracy(fit1_hc)[2]^2)*30

fit2_hc <- ses(books[,2], initial = "simple", alpha = 0.4, h=4)
SSE_fit2_hc <- (accuracy(fit2_hc)[2]^2)*30
summary(fit2_hc)
fit3_hc <- ses(books[,2], initial = "simple", alpha = 0.6, h=4)
SSE_fit3_hc <- (accuracy(fit3_hc)[2]^2)*30

fit4_hc <- ses(books[,2], initial = "simple", alpha = 0.8, h=4)
SSE_fit4_hc <- (accuracy(fit4_hc)[2]^2)*30

Metrics_Values_hc <- rbind.data.frame(accuracy(fit1_hc), accuracy(fit2_hc), accuracy(fit3_hc), 
                                   accuracy(fit4_hc)) 
rownames(Metrics_Values_hc) <- c("alpha = 0.2", "alpha = 0.4", "alpha = 0.6", "alpha = 0.8")
knitr::kable(Metrics_Values_hc, caption = "Metrics from each model")

SSE_Values_hc <- cbind.data.frame(SSE_fit1_hc, SSE_fit2_hc, SSE_fit3_hc, SSE_fit4_hc) 
colnames(SSE_Values_hc) <- c("alpha = 0.2", "alpha = 0.4", "alpha = 0.6", "alpha = 0.8")
rownames(SSE_Values_hc) <- "SSE"
knitr::kable(SSE_Values_hc, caption = "SSE values of each model")

autoplot(books[,2]) +
  autolayer(fitted(fit1_hc), series = "alpha = 0.2") +
autolayer(fitted(fit2_hc), series = "alpha = 0.4") +
autolayer(fitted(fit3_hc), series = "alpha = 0.6") +
  autolayer(fitted(fit4_hc), series = "alpha = 0.8") +
  xlab("Days") + ylab("Hardcover Books")

```


The summary statistic below is from SES model selected the optimal value of alpha. The model selects the optimal value of alpha = 0.3283. Forecast values are lower than than the results in 2 for alpha = 0.4.

```{r part_C, echo=F}
### Ch7.Q1.e) - Part C
fit5_hc <- ses(books[,2], h=4)
summary(fit5_hc)
SSE_fit5_hc <- data.frame((accuracy(fit5_hc)[2]^2)*30)
colnames(SSE_fit5_hc) <- c("alpha = 0.1685")
rownames(SSE_fit5_hc) <- "SSE Value"
knitr::kable(SSE_fit5_hc, caption = "SSE - SES Select")

```


The summary statistic below shows that with the initial = "optimal" option, we get the same alpha and initial states. There's no difference from SES selecting an optimal value without the option and after setting the optimal option.

```{r part_D, echo=F}
### Ch7.Q1.e) - Part D
fit6_hc <- ses(books[,2], initial = "optimal" ,h=4)
summary(fit6_hc)
SSE_fit6_hc <- data.frame((accuracy(fit6_hc)[2]^2)*30)
colnames(SSE_fit6_hc) <- c("alpha = 0.1685")
rownames(SSE_fit6_hc) <- "SSE Value"
knitr::kable(SSE_fit6_hc, caption = "SSE - Optimal Select")

```

## Question 2
### Ch7.Q2.a)

Table 9 shows the SSE value of paperback and hardback series obtained using Holt's linear method. These measures are much better than any of the SSE values obtained using SES. Earlier, we had doubts that data may have some trend behaviour. The result confirms that there's definitely trend behaviour present in the data. Hence, simple exponential smoothing may not be the best option for this kind of data.

```{r holtsTrend, echo=F}
### Ch7.Q2.a)
fit1_holts <- holt(books[,1], h = 4)
SSE_holts <- data.frame(sum(fit1_holts$residuals^2))
colnames(SSE_holts) <- c("Holt's Linear - Paperback")
rownames(SSE_holts) <- "SSE Value"

fit2_holts <- holt(books[,2], h = 4)
SSE_holts_2 <- data.frame(sum(fit2_holts$residuals^2))
colnames(SSE_holts_2) <- c("Holt's Linear - Hardcover")
rownames(SSE_holts_2) <- "SSE Value"

knitr::kable(cbind(SSE_holts,SSE_holts_2) , caption = "SSE Values")

```

### Ch7.Q2.b)

The figure below shows the forecast of Simple exponential smoothing and Holt's linear methods for paperback books. It appears that Holt's linear method performed better. Forecast from SES seems to be flat.

```{r compare_forecast, echo=F}
### Ch7.Q2.b)
autoplot(books[,1]) + 
  autolayer(fit5_pb$mean, series = "SES - Paperback") +
  autolayer(fit1_holts$mean, series = "Holts - Paperback") + 
  ggtitle("Forecast comparison SES vs Holt's for paperback series") +
  xlab("Days") +
  ylab("Books")
```

The figure below shows the forecast of Simple exponential smoothing and Holt's linear methods for hardcover books. Again, it appears that Holt's linear method performed better.

```{r compare_forecast2, echo=F}
### Ch7.Q2.b)
autoplot(books[,2]) + 
  autolayer(fit5_hc$mean, series = "SES - Hardcover") +
  autolayer(fit2_holts$mean, series = "Holts - Hardcover") + 
  ggtitle("Forecast comparison SES vs Holt's for hardcover series") +
  xlab("Days") +
  ylab("Books")

```

### Ch7.Q2.c)

The figures below shows the 95% prediction interval for the forecase for each series using Holt's and Simple Exponential Smoothing methods. Both the methods are forecasting within the prediction interval.


```{r pred_interval, echo=F}
### Ch7.Q2.c)
autoplot(fit1_holts) +
    autolayer(fit1_holts$mean, series = "Holt's Method") +
    autolayer(fit5_pb$mean, series = "SES Method") +
  ggtitle("Forecast from Holt's Method for Paperback Books") +
  xlab("Days") +
  ylab("Books")

autoplot(fit2_holts) +
    autolayer(fit2_holts$mean, series = "Holt's Method") +
    autolayer(fit5_hc$mean, series = "SES Method") +
  ggtitle("Forecast from Holt's Method for Hardcover Books") +
  xlab("Days") +
  ylab("Books")
```

## Question 3
### Ch7.Q3)

The table below give the metrics from each model. It shows that model with exponential trend gave the best RSME of 26.386. The figure below shows the forecast of each model. Again, it is quite evident that exponential trend forecase seems to be a lot better as compared to others.


```{r importdata, echo=F}
### Ch7.Q3)
data("eggs")

fit_eggs_1 <- holt(eggs, damped = T, h=100)
#summary(fit_eggs_1)
fit_eggs_2 <- holt(eggs, damped = T, exponential = T, h=100)
fit_eggs_3 <- holt(eggs, damped = F, exponential = T, h=100)
fit_eggs_4 <- holt(eggs, damped = T, exponential = T, 
                   alpha = 0.2, beta = 0.2 ,h=100)
fit_eggs_5 <- holt(eggs, damped = T, exponential = T, 
                   alpha = 0.4, beta = 0.4 ,h=100)
fit_eggs_6 <- holt(eggs, damped = F, exponential = F, 
                   alpha = 0.8, beta = 0.2 ,h=100)


metrics <- rbind(accuracy(fit_eggs_1),accuracy(fit_eggs_2),
                 accuracy(fit_eggs_3),accuracy(fit_eggs_4),
                 accuracy(fit_eggs_5),accuracy(fit_eggs_6))

rownames(metrics) <- c("Damped Holt's","Damped & Exp Holt's", "Exp Holt's",
                       "Damped & Exp Holt's; alpah/beta = 0.2",
                       "Damped & Exp Holt's; alpah/beta = 0.4/0.4",
                       "alpah/beta = 0.8/0.2")
knitr::kable(round(metrics,3), caption = "Metrics for each model")

eggs %>% 
    autoplot() +
    autolayer(fit_eggs_1$mean, series = "Damped Holt's") +
    autolayer(fit_eggs_2$mean, series = "Damped & Exp Holt's") +
      autolayer(fit_eggs_3$mean, series = "Exp Holt's") +
      autolayer(fit_eggs_4$mean, 
                series = "Damped & Exp Holt's; alpah/beta = 0.2") +
      autolayer(fit_eggs_5$mean, 
                series = "Damped & Exp Holt's; alpah/beta = 0.4/0.4") +
      autolayer(fit_eggs_6$mean, series = "alpah/beta = 0.8/0.2") +
    ggtitle("Forecasts from Holt's method") +
  guides(colour=guide_legend(title="Forecast")) +
  theme(legend.position="bottom")

```

## Question 4
### Ch7.Q4.a)

The figure below shows the plot of the quarterly UK passenger vehicle production from January 1977 to January 2005.The data in the figure below display seasonality as well as trend behaviour.

```{r data_import_4, echo=F}
### Ch7.Q4.a)
data("ukcars")
autoplot(ukcars) +
  ggtitle("Quarterly UK passenger vehicle production") +
  xlab("Year") +
  ylab("Cars") +
  theme_bw()

```


### Ch7.Q4.b)

The figure below shows trend-cycle and seasonal indices of the STL decomposition. We can see the increasing trend from the beginning of 1980 to 1998. Earlier we mentioned that there are some seasonality in the data. Here, we can clearly see the seasonal effects in the third panel. The large gray bar in the third panel shows that variation in the seasonal component is small as compared to the variation in the data.

```{r stlDecom, echo=F, fig.height=7, fig.width=6}
### Ch7.Q4.b)

fit_stl <- stl(ukcars, t.window=13, s.window="periodic", robust=TRUE)

fit_stl %>% 
  autoplot() +
    ggtitle("Robust STL decomposition") +
    theme_bw()

```

The figure below shows the plot of the seasonally adjusted data obtained using the robust STL decomposition.

```{r seasAdj, echo=F}
### Ch7.Q4.b)
fit_stl %>% 
  seasadj() %>% 
  autoplot() +
  ggtitle("Seasonally adjusted data") +
  theme_bw()

```

### Ch7.Q4.c)

The table below shows the metrics for an additive damped trend method applied to the seasonally adjusted data and reseasonalized forecast.

```{r fcast_damped, echo=F}
### Ch7.Q4.c)
seasAdj_ts <- seasadj(fit_stl)

fit_damp <- holt(seasAdj_ts, damped = T, h=8)
acc_damp <- accuracy(fit_damp)
rownames(acc_damp) <- "Additive Damped"

acc_reseason <- accuracy(forecast(fit_stl))
rownames(acc_reseason) <- "Reseasonalize Forecast"

knitr::kable(rbind(acc_damp, acc_reseason), caption = "Metrics")

```


### Ch7.Q4.d)

The table below shows the metrics from the Holt's linear method applied to the seasonally adjusted data and reseasonalized forecast.

```{r fcast_linearHolt, echo=F}
### Ch7.Q4.d)
seasAdj_ts <- seasadj(fit_stl)

fit_holt <- holt(seasAdj_ts, h=8)
acc_holt <- accuracy(fit_holt)
rownames(acc_holt) <- "Holt's linear"

acc_reseason_ln <- accuracy(forecast(fit_stl))
rownames(acc_reseason_ln) <- "Reseasonalize Forecast"

knitr::kable(rbind(acc_holt, acc_reseason_ln), caption = "Metrics")

```


### Ch7.Q4.e)

The summary below shows the ETS(A,A,A) seasonal model with additive errors. 

The table below shows the metrics for an additive damped trend method applied to the seasonally adjusted data and reseasonalized forecast.

```{r fcast_ets, echo=F}
### Ch7.Q4.e)
fit_ets_A <- ets(ukcars, model = "AAA")
summary(fit_ets_A)
acc_ets <- accuracy(fit_ets_A)
rownames(acc_ets) <- "ETS"
#knitr::kable(acc_ets, caption = "Metrics")

```

### Ch7.Q4.f)

Based on the table below, it seems like ETS model had a better in-sample fit.

```{r compare_rmse, echo=F}
### Ch7.Q4.f)
knitr::kable(rbind(acc_damp,acc_holt, acc_ets), caption = "Metrics")

```

### Ch7.Q4.e)

The forecasts generated Holt's linear method approach display a constant trend (increasing or decreasing) indefinitely into the future. Generally, this method over-forecast for longer forecast horizons. However, in our case, we are only forecasting for 4 additional days. Therefore, our forecast doesn't seem to over-forecast and is pretty close to the forecast of other methods. The forecast generated by additive damped trend seems to perform better over Holt's linear method. We got a better RMSE. However, in this cast, ETS method with additive seasonal component and additive error seems to perform the best.

# Chapter 8
## Question 1







## Appendix I: R Code

```{r show_code, ref.label=knitr::all_labels(), echo=T, eval=F}



```


