---
title: "Predict_413_Sec55_Homework_2"
author: "Singh, Gurjeet"
date: "February 18, 2018"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    fig_width: 9
    fig_height: 5
    fig_caption: true
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
---

\pagebreak
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE )
library(fpp)
library(tidyverse)

```

# Chapter 7
## Question 1
### Ch7.Q1.a)

The figure below shows the plot of the daily sales of paperback and hardcover books at the same store. The data in the figure below do not display any seasonality for paperback and hardcover books. However, there could some trend here. We will know more once we plug this data into various models.

```{r data_import, echo=F}
### Ch7.Q1.a)
data("books")
autoplot(books) +
  ggtitle("Daily sales of paperback and hardcover books at the same store")

```

### Ch7.Q1.b)

The Table 1 below shows the various matrics from each SES models with different alpha. It appears that as alpha increases, the error increases as well. Hence, alpha = 0.2 works best.

The Table 2 shows the SSE for each models using different alpha.

The figure below shows the four different sets of forecasts.

```{r simple, echo=F}
### Ch7.Q1.b)
fit1_pb <- ses(books[,1], initial = "simple", alpha = 0.2, h=4)
SSE_fit1 <- (accuracy(fit1_pb)[2]^2)*30

fit2_pb <- ses(books[,1], initial = "simple", alpha = 0.4, h=4)
SSE_fit2 <- (accuracy(fit2_pb)[2]^2)*30

fit3_pb <- ses(books[,1], initial = "simple", alpha = 0.6, h=4)
SSE_fit3 <- (accuracy(fit3_pb)[2]^2)*30

fit4_pb <- ses(books[,1], initial = "simple", alpha = 0.8, h=4)
SSE_fit4 <- (accuracy(fit4_pb)[2]^2)*30

Metrics_Values <- rbind.data.frame(accuracy(fit1_pb), accuracy(fit2_pb), accuracy(fit3_pb), 
                                   accuracy(fit4_pb)) 
rownames(Metrics_Values) <- c("alpha = 0.2", "alpha = 0.4", "alpha = 0.6", "alpha = 0.8")
knitr::kable(Metrics_Values, caption = "Metrics from each model")

SSE_Values <- cbind.data.frame(SSE_fit1, SSE_fit2, SSE_fit3, SSE_fit4) 
colnames(SSE_Values) <- c("alpha = 0.2", "alpha = 0.4", "alpha = 0.6", "alpha = 0.8")
rownames(SSE_Values) <- "SSE"
knitr::kable(SSE_Values, caption = "SSE values of each model")

autoplot(books[,1]) +
  autolayer(fitted(fit1_pb), series = "alpha = 0.2") +
autolayer(fitted(fit2_pb), series = "alpha = 0.4") +
autolayer(fitted(fit3_pb), series = "alpha = 0.6") +
  autolayer(fitted(fit4_pb), series = "alpha = 0.8") +
  xlab("Days") + ylab("Paperback Books")

```


### Ch7.Q1.c)

The summary statistic below is from SES model selected the optimal value of alpha. As we mentioned earlier that lower value of alpha gives us the best model, it is quite evident with the result that alpha = 0.1685 gave us the lowest RMSE and SSE.

```{r ses_select, echo=F}
### Ch7.Q1.c)
fit5_pb <- ses(books[,1], h=4)
summary(fit5_pb)
SSE_fit5 <- data.frame((accuracy(fit5_pb)[2]^2)*30)
colnames(SSE_fit5) <- c("alpha = 0.1685")
rownames(SSE_fit5) <- "SSE Value"
knitr::kable(SSE_fit5, caption = "SSE - SES Select")

```


### Ch7.Q1.d)

The summary statistic below shows that with the initial = "optimal" option, we get the same alpha and initial states. There's no difference from SES selecting an optimal value without the option and after setting the optimal option.

```{r ses_select_opt, echo=F}
### Ch7.Q1.d)
fit6_pb <- ses(books[,1], initial = "optimal" ,h=4)
summary(fit6_pb)
SSE_fit6 <- data.frame((accuracy(fit6_pb)[2]^2)*30)
colnames(SSE_fit6) <- c("alpha = 0.1685")
rownames(SSE_fit6) <- "SSE Value"
knitr::kable(SSE_fit6, caption = "SSE - Optimal Select")

```

### Ch7.Q1.e)

We run SES model for Hardcover books. The Table 5 below shows the various matrics from each SES models with different alpha. When alpha = 0.4, the RMSE is the lowest. Hence, forecast works best.

The Table 6 shows the SSE for each models using different alpha. It is clear that alpha = 0.4 gives us the best forecast.

The figure below shows the four different sets of forecasts.

```{r part_B, echo=F}
### Ch7.Q1.e) - Part B
fit1_hc <- ses(books[,2], initial = "simple", alpha = 0.2, h=4)
#summary(fit1_pb)
SSE_fit1_hc <- (accuracy(fit1_hc)[2]^2)*30

fit2_hc <- ses(books[,2], initial = "simple", alpha = 0.4, h=4)
SSE_fit2_hc <- (accuracy(fit2_hc)[2]^2)*30
summary(fit2_hc)
fit3_hc <- ses(books[,2], initial = "simple", alpha = 0.6, h=4)
SSE_fit3_hc <- (accuracy(fit3_hc)[2]^2)*30

fit4_hc <- ses(books[,2], initial = "simple", alpha = 0.8, h=4)
SSE_fit4_hc <- (accuracy(fit4_hc)[2]^2)*30

Metrics_Values_hc <- rbind.data.frame(accuracy(fit1_hc), accuracy(fit2_hc), accuracy(fit3_hc), 
                                   accuracy(fit4_hc)) 
rownames(Metrics_Values_hc) <- c("alpha = 0.2", "alpha = 0.4", "alpha = 0.6", "alpha = 0.8")
knitr::kable(Metrics_Values_hc, caption = "Metrics from each model")

SSE_Values_hc <- cbind.data.frame(SSE_fit1_hc, SSE_fit2_hc, SSE_fit3_hc, SSE_fit4_hc) 
colnames(SSE_Values_hc) <- c("alpha = 0.2", "alpha = 0.4", "alpha = 0.6", "alpha = 0.8")
rownames(SSE_Values_hc) <- "SSE"
knitr::kable(SSE_Values_hc, caption = "SSE values of each model")

autoplot(books[,2]) +
  autolayer(fitted(fit1_hc), series = "alpha = 0.2") +
autolayer(fitted(fit2_hc), series = "alpha = 0.4") +
autolayer(fitted(fit3_hc), series = "alpha = 0.6") +
  autolayer(fitted(fit4_hc), series = "alpha = 0.8") +
  xlab("Days") + ylab("Hardcover Books")

```


The summary statistic below is from SES model selected the optimal value of alpha. The model selects the optimal value of alpha = 0.3283. Forecast values are lower than than the results in 2 for alpha = 0.4.

```{r part_C, echo=F}
### Ch7.Q1.e) - Part C
fit5_hc <- ses(books[,2], h=4)
summary(fit5_hc)
SSE_fit5_hc <- data.frame((accuracy(fit5_hc)[2]^2)*30)
colnames(SSE_fit5_hc) <- c("alpha = 0.1685")
rownames(SSE_fit5_hc) <- "SSE Value"
knitr::kable(SSE_fit5_hc, caption = "SSE - SES Select")

```


The summary statistic below shows that with the initial = "optimal" option, we get the same alpha and initial states. There's no difference from SES selecting an optimal value without the option and after setting the optimal option.

```{r part_D, echo=F}
### Ch7.Q1.e) - Part D
fit6_hc <- ses(books[,2], initial = "optimal" ,h=4)
summary(fit6_hc)
SSE_fit6_hc <- data.frame((accuracy(fit6_hc)[2]^2)*30)
colnames(SSE_fit6_hc) <- c("alpha = 0.1685")
rownames(SSE_fit6_hc) <- "SSE Value"
knitr::kable(SSE_fit6_hc, caption = "SSE - Optimal Select")

```

## Question 2
### Ch7.Q2.a)

Table 9 shows the SSE value of paperback and hardback series obtained using Holt's linear method. These measures are much better than any of the SSE values obtained using SES. Earlier, we had doubts that data may have some trend behaviour. The result confirms that there's definitely trend behaviour present in the data. Hence, simple exponential smoothing may not be the best option for this kind of data.

```{r holtsTrend, echo=F}
### Ch7.Q2.a)
fit1_holts <- holt(books[,1], h = 4)
SSE_holts <- data.frame(sum(fit1_holts$residuals^2))
colnames(SSE_holts) <- c("Holt's Linear - Paperback")
rownames(SSE_holts) <- "SSE Value"

fit2_holts <- holt(books[,2], h = 4)
SSE_holts_2 <- data.frame(sum(fit2_holts$residuals^2))
colnames(SSE_holts_2) <- c("Holt's Linear - Hardcover")
rownames(SSE_holts_2) <- "SSE Value"

knitr::kable(cbind(SSE_holts,SSE_holts_2) , caption = "SSE Values")

```

### Ch7.Q2.b)

The figure below shows the forecast of Simple exponential smoothing and Holt's linear methods for paperback books. It appears that Holt's linear method performed better. Forecast from SES seems to be flat.

```{r compare_forecast, echo=F}
### Ch7.Q2.b)
autoplot(books[,1]) + 
  autolayer(fit5_pb$mean, series = "SES - Paperback") +
  autolayer(fit1_holts$mean, series = "Holts - Paperback") + 
  ggtitle("Forecast comparison SES vs Holt's for paperback series") +
  xlab("Days") +
  ylab("Books")
```

The figure below shows the forecast of Simple exponential smoothing and Holt's linear methods for hardcover books. Again, it appears that Holt's linear method performed better.

```{r compare_forecast2, echo=F}
### Ch7.Q2.b)
autoplot(books[,2]) + 
  autolayer(fit5_hc$mean, series = "SES - Hardcover") +
  autolayer(fit2_holts$mean, series = "Holts - Hardcover") + 
  ggtitle("Forecast comparison SES vs Holt's for hardcover series") +
  xlab("Days") +
  ylab("Books")

```

### Ch7.Q2.c)

The figures below shows the 95% prediction interval for the forecase for each series using Holt's and Simple Exponential Smoothing methods. Both the methods are forecasting within the prediction interval.


```{r pred_interval, echo=F}
### Ch7.Q2.c)
autoplot(fit1_holts) +
    autolayer(fit1_holts$mean, series = "Holt's Method") +
    autolayer(fit5_pb$mean, series = "SES Method") +
  ggtitle("Forecast from Holt's Method for Paperback Books") +
  xlab("Days") +
  ylab("Books")

autoplot(fit2_holts) +
    autolayer(fit2_holts$mean, series = "Holt's Method") +
    autolayer(fit5_hc$mean, series = "SES Method") +
  ggtitle("Forecast from Holt's Method for Hardcover Books") +
  xlab("Days") +
  ylab("Books")
```

## Question 3
### Ch7.Q3)

The table below give the metrics from each model. It shows that model with exponential trend gave the best RSME of 26.386. The figure below shows the forecast of each model. Again, it is quite evident that exponential trend forecase seems to be a lot better as compared to others.


```{r importdata, echo=F}
### Ch7.Q3)
data("eggs")

fit_eggs_1 <- holt(eggs, damped = T, h=100)
#summary(fit_eggs_1)
fit_eggs_2 <- holt(eggs, damped = T, exponential = T, h=100)
fit_eggs_3 <- holt(eggs, damped = F, exponential = T, h=100)
fit_eggs_4 <- holt(eggs, damped = T, exponential = T, 
                   alpha = 0.2, beta = 0.2 ,h=100)
fit_eggs_5 <- holt(eggs, damped = T, exponential = T, 
                   alpha = 0.4, beta = 0.4 ,h=100)
fit_eggs_6 <- holt(eggs, damped = F, exponential = F, 
                   alpha = 0.8, beta = 0.2 ,h=100)


metrics <- rbind(accuracy(fit_eggs_1),accuracy(fit_eggs_2),
                 accuracy(fit_eggs_3),accuracy(fit_eggs_4),
                 accuracy(fit_eggs_5),accuracy(fit_eggs_6))

rownames(metrics) <- c("Damped Holt's","Damped & Exp Holt's", "Exp Holt's",
                       "Damped & Exp Holt's; alpah/beta = 0.2",
                       "Damped & Exp Holt's; alpah/beta = 0.4/0.4",
                       "alpah/beta = 0.8/0.2")
knitr::kable(round(metrics,3), caption = "Metrics for each model")

eggs %>% 
    autoplot() +
    autolayer(fit_eggs_1$mean, series = "Damped Holt's") +
    autolayer(fit_eggs_2$mean, series = "Damped & Exp Holt's") +
      autolayer(fit_eggs_3$mean, series = "Exp Holt's") +
      autolayer(fit_eggs_4$mean, 
                series = "Damped & Exp Holt's; alpah/beta = 0.2") +
      autolayer(fit_eggs_5$mean, 
                series = "Damped & Exp Holt's; alpah/beta = 0.4/0.4") +
      autolayer(fit_eggs_6$mean, series = "alpah/beta = 0.8/0.2") +
    ggtitle("Forecasts from Holt's method") +
  guides(colour=guide_legend(title="Forecast")) +
  theme(legend.position="bottom")

```

## Question 4
### Ch7.Q4.a)

The figure below shows the plot of the quarterly UK passenger vehicle production from January 1977 to January 2005.The data in the figure below display seasonality as well as trend behaviour.

```{r data_import_4, echo=F}
### Ch7.Q4.a)
data("ukcars")
autoplot(ukcars) +
  ggtitle("Quarterly UK passenger vehicle production") +
  xlab("Year") +
  ylab("Cars") +
  theme_bw()

```


### Ch7.Q4.b)

The figure below shows trend-cycle and seasonal indices of the STL decomposition. We can see the increasing trend from the beginning of 1980 to 1998. Earlier we mentioned that there are some seasonality in the data. Here, we can clearly see the seasonal effects in the third panel. The large gray bar in the third panel shows that variation in the seasonal component is small as compared to the variation in the data.

```{r stlDecom, echo=F, fig.height=7, fig.width=6}
### Ch7.Q4.b)

fit_stl <- stl(ukcars, t.window=13, s.window="periodic", robust=TRUE)

fit_stl %>% 
  autoplot() +
    ggtitle("Robust STL decomposition") +
    theme_bw()

```

The figure below shows the plot of the seasonally adjusted data obtained using the robust STL decomposition.

```{r seasAdj, echo=F}
### Ch7.Q4.b)
fit_stl %>% 
  seasadj() %>% 
  autoplot() +
  ggtitle("Seasonally adjusted data") +
  theme_bw()

```

### Ch7.Q4.c)

The table below shows the metrics for an additive damped trend method applied to the seasonally adjusted data and reseasonalized forecast.

```{r fcast_damped, echo=F}
### Ch7.Q4.c)
seasAdj_ts <- seasadj(fit_stl)

fit_damp <- holt(seasAdj_ts, damped = T, h=8)
acc_damp <- accuracy(fit_damp)
rownames(acc_damp) <- "Additive Damped"

acc_reseason <- accuracy(forecast(fit_stl))
rownames(acc_reseason) <- "Reseasonalize Forecast"

knitr::kable(rbind(acc_damp, acc_reseason), caption = "Metrics")

```


### Ch7.Q4.d)

The table below shows the metrics from the Holt's linear method applied to the seasonally adjusted data and reseasonalized forecast.

```{r fcast_linearHolt, echo=F}
### Ch7.Q4.d)
seasAdj_ts <- seasadj(fit_stl)

fit_holt <- holt(seasAdj_ts, h=8)
acc_holt <- accuracy(fit_holt)
rownames(acc_holt) <- "Holt's linear"

acc_reseason_ln <- accuracy(forecast(fit_stl))
rownames(acc_reseason_ln) <- "Reseasonalize Forecast"

knitr::kable(rbind(acc_holt, acc_reseason_ln), caption = "Metrics")

```


### Ch7.Q4.e)

The summary below shows the ETS(A,A,A) seasonal model with additive errors. 

The table below shows the metrics for an additive damped trend method applied to the seasonally adjusted data and reseasonalized forecast.

```{r fcast_ets, echo=F}
### Ch7.Q4.e)
fit_ets_A <- ets(ukcars, model = "AAA")
summary(fit_ets_A)
acc_ets <- accuracy(fit_ets_A)
rownames(acc_ets) <- "ETS"
#knitr::kable(acc_ets, caption = "Metrics")

```

### Ch7.Q4.f)

Based on the table below, it seems like ETS model had a better in-sample fit.

```{r compare_rmse, echo=F}
### Ch7.Q4.f)
knitr::kable(rbind(acc_damp,acc_holt, acc_ets), caption = "Metrics")

```

### Ch7.Q4.e)

The forecasts generated Holt's linear method approach display a constant trend (increasing or decreasing) indefinitely into the future. Generally, this method over-forecast for longer forecast horizons. However, in our case, we are only forecasting for 4 additional days. Therefore, our forecast doesn't seem to over-forecast and is pretty close to the forecast of other methods. The forecast generated by additive damped trend seems to perform better over Holt's linear method. We got a better RMSE. However, in this cast, ETS method with additive seasonal component and additive error seems to perform the best.

# Chapter 8
## Question 5
### Ch8.Q5.a&b)

THe plot below show the time series plot of the data generated from an AR(1) model with Phi = 0.6 and sigma squared = 1.

```{r simpleARIMA, echo=F}
y <- ts(numeric(100))
e <- rnorm(100)
for(i in 2:100){
  y[i] <- 0.6*y[i-1] + e[i]
}
autoplot(y) +
  ggtitle("Time Series Plot when Phi = 0.6, sigma square = 1") +
    theme_bw()
```

The plot below show the time series plot of the data generated from an AR(1) model with Phi = 0 and sigma squared = 1. By changing the Phi, it appears that the seasonal effect got more closer.

```{r simpleARIMA2, echo=F}
y <- ts(numeric(100))
e <- rnorm(100)
for(i in 2:100){
  y[i] <- 0*y[i-1] + e[i]
}
autoplot(y) +
  ggtitle("Time Series Plot when Phi = 0, sigma square = 1") +
  theme_bw()
```

### Ch8.Q5.c&d)

THe plot below show the time series plot of the data generated from an MA(1) model with Phi = 0.6 and sigma squared = 1.

The second plot below show the time series plot of the data generated from an MA(1) model with Phi = 0 and sigma squared = 1. By changing the Phi, it appears that the seasonal effect got more closer.

```{r MA1, echo=F}
y <- ts(numeric(100))
e <- rnorm(100)
for(i in 2:100){
  y[i] <- e[i] + 0.6*e[i-1]
}
autoplot(y) +
  ggtitle("Time Series Plot of MA(1) when Phi = 0.6, sigma square = 1") +
  theme_bw()

y <- ts(numeric(100))
e <- rnorm(100)
for(i in 2:100){
  y[i] <- e[i] + 0*e[i-1]
}
autoplot(y) +
  ggtitle("Time Series Plot of MA(1) when Phi = 0, sigma square = 1") +
  theme_bw()
```


### Ch8.Q5.e,f,&g)

The top plot below show the time series plot of the data generated from an ARMA(1,1) model with Phi = 0.6 and Theta = 0.6 and sigma sqr = 1. The second plot below show the time series plot of the data generated from an AR(2) model with Phi = -0.8 and Phi = 0.3 and sigma sqr = 1. It appears that the second plot is a non-stationary series while the first one seem to be a stationary series.


```{r ARMA11, echo=F}
y <- ts(numeric(100))
e <- rnorm(100)
for(i in 2:100){
  y[i] <-  0.6*y[i-1] + 0.6*e[i-1] + e[i]
}
P1 <- autoplot(y) +
  ggtitle("Time Series Plot of ARMA(1,1) when Phi = 0.6 and Theta=0.6 and sigma sqr=1") +
  theme_bw()

y <- ts(numeric(100))
e <- rnorm(100)
for(i in 3:100){
  y[i] <- y[i-1]*(-0.8) + 0.3*y[i-2] + e[i]
}
P2 <- autoplot(y) +
  ggtitle("Time Series Plot of AR(2) when Phi = -0.8 and Phi = 0.3  and sigma sqr=1") +
  theme_bw()

gridExtra::grid.arrange(P1, P2, nrow=2)
```

## Question 6
### Ch8.Q6.a)

The figure below shows the time series plot of the number of wonmen murdered each year in the US.

```{r ARIMA1, echo=F}
data("wmurders")
#View(wmurders)

autoplot(wmurders) +
  ggtitle("Number of women murdered each year in the US") +
  theme_bw() +
  xlab("Year")

```

The figure below shows the ACF and PACF plots for the number of women murdered each year in the US. In the figure below, it appears that the data follow an ARIMA(p,d,0) model because the plot of the differenced data show the ACF is exponentially decaying and there is a significant spike at lag p in PACF, but none beyond lag p. Therefore, in ACF plot, there are nine (9) spikes decreasing with the lag and then no significant spikes thereafter. Hence, the pattern in the first nine spikes is what we would expect from an ARIMA(9,0,0) as the ACF tends to decay exponentially.


```{r ARIMA_ACF_PACF, echo=F}
gg1 <- ggAcf(wmurders, main="ACF plot")
gg2 <- ggPacf(wmurders, main="PACF plot")

gridExtra::grid.arrange(gg1,gg2,nrow = 2)
```

### Ch8.Q6.b)

Based on the results from ACF and PACF plots, it doesn't seem to be a need for constant in the model because the long term forecasts will not go to the mean of the data, follow a straight line, or follow a quadratic trend.


### Ch8.Q6.c)

ARIMA(p,d,q) model is given by: 

((1 - B)^d)*Yt = mu + (theta(B)/phi(B))at \newline

Where, \newline
t - indexes time\newline
mu - is the mean term \newline
B - is the backshift operator; that is, BXt=Xt-1 \newline
phi(B) - is the autoregressive operator \newline
theta(B) - is the moving-average operator \newline
at - is the independent disturbance, also called the random error \newline

The ARIMA(9,0,0) model in terms of the backshift operator is shown below:

((1 - B)^d)*Yt = mu + ((1 - theta0(B))/(1 - phi1(B) - ... - phi9(B)^9))at \newline


### Ch8.Q6.d)

We create three models, auto.arima, ARIMA(9,0,0) - our model, and ARIMA(9,1,0). Two of the models created is to compare with our model. Below is the summary from each model. When comparing the RMSE for each model, it seems like our ARIMA(9,0,0) model performed the best.

```{r ARIMA_fit, echo=F}
### Ch8.Q6.d)
summary(auto.arima(wmurders))
summary(Arima(wmurders, order = c(9,0,0)))
summary(Arima(wmurders, order = c(9,1,0)))

```

The figure below shows the residuals from ARIMA(9,0,0) model with non-zero mean. In the ACF plot, all the spikes are now within the significance limits, and so the residual apprea to be white noise. Therefore, the model is satisfactory.

```{r ARIMA_res, echo=F}
checkresiduals(arima(wmurders, order = c(9,0,0)))

```
### Ch8.Q6.e&f)

The figure below shows the forecast for the next three years with the 80% and 95% prediction interval.

```{r ARIMA_fcast, echo=F}
fcast <- forecast(arima(wmurders, order = c(9,0,0)), h=3)

autoplot(fcast) +
  theme_bw()
```

### Ch8.Q6.g)

In section Ch8.Q6.d), I have compared auto.arima with our model. The auto.arima do not give us the same model. The model produced by auto.arima is ARIMA(1,2,1) which did not perform better than our model. The RMSE is little higher than our model. Therefore, ARIMA(9,0,0) model is the better model.



## Question 7
### Ch8.Q7.a)

The figure below shows the quarterly number of international tourists to Australia for the period 1999-2010. The data follows the seasonal patterns and have the increasing trend.

```{r data_AUS, echo=F}
data("austourists")
autoplot(austourists) +
  ggtitle("Quarterly number of international tourists to Australia for the period 1999-2010") +
  theme_bw() +
  xlab("Year")
```

### Ch8.Q7.b&c)

The figure below shows the ACF and PACF plots for the quarterly number of international tourists to Australia for the period 1999-2010. In the figure below, ACF plot shows that the lag is every fourth term because there are spikes at lag 4, lag 8, lag 12, and lag 16 and is exponentially decaying in the deasonal lags of the ACF. Hence, the data will follow an ARIMA(0,0,0)(1,0,0)4 model.

data follow an ARIMA(p,d,0) model because the plot of the differenced data show the ACF is exponentially decaying and there is a significant spike at lag p in PACF, but none beyond lag p. Therefore, in ACF plot, there are nine (9) spikes decreasing with the lag and then no significant spikes thereafter. Hence, the pattern in the first nine spikes is what we would expect from an ARIMA(9,0,0) as the ACF tends to decay exponentially.


```{r ACF_PACF, echo=F}
gg1 <- ggAcf(austourists, main="ACF plot")
gg2 <- ggPacf(austourists, main="PACF plot")

gridExtra::grid.arrange(gg1,gg2,nrow = 2)
```

### Ch8.Q7.d)

The figure below shows the seasonally differenced data along with ACF and PACF plots. There is a significant spike at lag 1 in the ACF suggests a non-seasonal MA(1) component, and the significant spike at lag 4 in the ACF suggests a seasonal MA(1) component. Therefore, we begin with an ARIMA(0,1,1)(0,1,1)[4] model.

```{r plotseas, echo=F}

austourists %>% 
    diff(lag=4) %>%
    ggtsdisplay()
```


### Ch8.Q7.e)

The summary below shows the summaries of auto.arima and ARIMA(0,1,1)(0,1,1)[4]. The auto.arima gave us the model ARIMA(1,0,0)(1,1,0)[4] with drift. The auto.arima model is the better model for this data because AIC and RMSE are lower than the ARIMA(0,1,1)(0,1,1)[4] model.

```{r autoARima, echo=F}
atArm <- auto.arima(austourists)
fitarm <- Arima(austourists, order = c(0,1,1), seasonal = list(order = c(0,1,1), period = 4))
# fitarm <- Arima(austourists, order = c(0,1,1), seasonal = list(order = c(0,1,1)))
summary(atArm)
summary(fitarm)
```


## Appendix I: R Code

```{r show_code, ref.label=knitr::all_labels(), echo=T, eval=F}



```






















